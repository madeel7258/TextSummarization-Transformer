# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5ugpr_9EJtl3Bq88S6RCgWEFcljVdse
"""

!pip install tensorflow torch transformers datasets nltk rouge-score scikit-learn

from datasets import load_dataset
from transformers import BartTokenizer

# Load the dataset
dataset = load_dataset('cnn_dailymail', '3.0.0')

# Initialize the tokenizer
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')

# Preprocessing function
def preprocess_function(examples):
    inputs = tokenizer(examples['article'], max_length=1024, truncation=True)
    outputs = tokenizer(examples['highlights'], max_length=150, truncation=True)
    inputs['labels'] = outputs['input_ids']
    return inputs

# Apply preprocessing
processed_dataset = dataset.map(preprocess_function, batched=True)

from transformers import BartForConditionalGeneration, Trainer, TrainingArguments

# Load the pre-trained BART model
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Training arguments
training_args = TrainingArguments(
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    output_dir='./results',
    evaluation_strategy='epoch',
    logging_dir='./logs',
    num_train_epochs=3,
    save_total_limit=1,
    logging_steps=100,
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=processed_dataset['train'],
    eval_dataset=processed_dataset['validation'],
)

# Train the model
trainer.train()

from datasets import load_metric

rouge = load_metric('rouge')

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = tokenizer.batch_decode(logits, skip_special_tokens=True)
    references = tokenizer.batch_decode(labels, skip_special_tokens=True)
    return rouge.compute(predictions=predictions, references=references)

trainer.compute_metrics = compute_metrics
eval_results = trainer.evaluate()
print(eval_results)

from datasets import load_metric

rouge = load_metric('rouge')

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = tokenizer.batch_decode(logits, skip_special_tokens=True)
    references = tokenizer.batch_decode(labels, skip_special_tokens=True)
    return rouge.compute(predictions=predictions, references=references)

trainer.compute_metrics = compute_metrics
eval_results = trainer.evaluate()
print(eval_results)

